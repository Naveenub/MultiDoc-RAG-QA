# **Multi-Document RAG QA System**

Multi-Document RAG QA System is a research-grade, open-source platform designed for **question answering across multiple documents** using Retrieval-Augmented Generation (RAG). It is engineered to be universal, scalable, ML-driven, and explainableâ€”not just another document search tool.

This is not a simple search engine. It is a **full end-to-end system** with multi-document ingestion, embedding pipelines, vector DB retrieval, LLM-based QA, RAG explanations, evaluation metrics, and interactive UI.

---

ğŸš€ **Why This System Exists**

Current limitations in document QA systems:

* No open-source, research-grade multi-document QA pipeline
* No universal ingestion for PDFs, DOCX, TXT, or other file types
* No explainable reasoning when the system fails to answer accurately

This project addresses these gaps by providing:

* ML-assisted retrieval for heterogeneous documents
* Multi-stage RAG pipelines for answer generation
* Explainable reasoning using RAG to prevent hallucination
* Transparent evaluation with QA metrics and benchmarks
* Reproducible, production-ready deployment

---

ğŸ§  **Core Design Goals**

* ğŸ§© **Universal** â€“ supports PDF, DOCX, TXT, and more
* âš¡ **Adaptive & Efficient** â€“ retrieves and ranks relevant documents intelligently
* ğŸ” **Explainable** â€“ RAG provides reasoning and citations
* ğŸ¯ **Benchmark-first** â€“ evaluates QA performance on multi-document corpora
* ğŸ› ï¸ **Tool-aware** â€“ integrates logs, embeddings, and file context
* ğŸ”“ **Fully open** â€“ MIT / Apache 2.0 license

---

ğŸ“ **System Overview**

The system treats QA as a **decision and retrieval problem** rather than just text generation.

| Stage                | Description                                                               |
| -------------------- | ------------------------------------------------------------------------- |
| Ingestion            | Reads documents, extracts metadata, text, and structure                   |
| Feature Extraction   | Chunking, tokenization, embedding creation                                |
| Vector DB Storage    | FAISS / Pinecone to store embeddings for retrieval                        |
| Retriever            | Finds relevant chunks for queries                                         |
| LLM QA Pipeline      | Generates context-aware answers from retrieved content                    |
| Explainer (RAG)      | Provides reasoning and citations when answers are incomplete or uncertain |
| Evaluator            | Computes F1, Exact Match, ROUGE, BLEU, hallucination metrics              |
| Frontend Interaction | React-based interface for uploads, queries, and answers                   |

---

ğŸ“Š **ML & Embedding Overview**

The ML components do not answer questions directly but **guide retrieval and ranking**:

| Attribute  | Value                                                      |
| ---------- | ---------------------------------------------------------- |
| Model type | Random Forest / Transformer embeddings                     |
| Inputs     | Chunk embeddings, document metadata, prior query relevance |
| Outputs    | Ranked documents, predicted relevance scores               |
| Libraries  | Hugging Face, OpenAI embeddings, scikit-learn              |
| License    | MIT / Apache 2.0                                           |

---

ğŸ” **Retrieval-Augmented Generation (RAG)**

RAG ensures **accurate, explainable answers**:

* Uses embeddings and historical document context
* References only retrieved documents to prevent hallucination
* Generates actionable, human-readable explanations for uncertain answers
* Supports multi-document queries with context merging

---

ğŸ—ï¸ **Tech Stack**

| Layer              | Choice                               |
| ------------------ | ------------------------------------ |
| Backend            | FastAPI, Python 3.11                 |
| ML & Embeddings    | Hugging Face, OpenAI, scikit-learn   |
| Vector DB          | FAISS, Pinecone                      |
| LLM QA Pipeline    | OpenAI GPT / LLaMA or similar        |
| RAG                | LangChain + FAISS / Chroma           |
| Frontend UI        | React + Tailwind                     |
| PDF / DOCX Parsing | PyMuPDF, python-docx                 |
| Evaluation         | QA metrics & hallucination detection |
| Deployment         | Docker, Docker Compose, AWS EC2      |

---

ğŸ§± **Repository Structure**

```
multi-doc-rag-qa/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # FastAPI main server
â”‚   â”œâ”€â”€ config.py               # Configs (DB, embeddings, LLM)
â”‚   â”œâ”€â”€ ingest.py               # Document ingestion pipeline
â”‚   â”œâ”€â”€ retriever.py            # Vector DB retrieval
â”‚   â”œâ”€â”€ llm.py                  # LLM query handling
â”‚   â”œâ”€â”€ evaluator.py            # QA evaluation & metrics
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ file_loader.py      # PDF, DOCX, TXT loaders
â”‚       â”œâ”€â”€ text_splitter.py    # Chunking & tokenization
â”‚       â”œâ”€â”€ embedding_utils.py  # Embedding creation & DB insertion
â”‚       â””â”€â”€ logger.py           # Logging utility
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ index.jsx
â”‚       â”œâ”€â”€ App.jsx
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚       â”‚   â”œâ”€â”€ FileUploader.jsx
â”‚       â”‚   â”œâ”€â”€ QueryInput.jsx
â”‚       â”‚   â””â”€â”€ EvaluationPanel.jsx
â”‚       â””â”€â”€ services/
â”‚           â”œâ”€â”€ api.js          # API calls to backend
â”‚           â””â”€â”€ utils.js
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”‚   â””â”€â”€ embedding_pipeline.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ local_models.py
â”‚   â””â”€â”€ training/
â”‚       â””â”€â”€ model_finetune.py
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ multi_doc_rag.py
â”‚   â”‚   â”œâ”€â”€ streaming_rag.py
â”‚   â”‚   â””â”€â”€ evaluation_rag.py
â”‚   â””â”€â”€ vector_db/
â”‚       â”œâ”€â”€ faiss_db.py         # FAISS vector DB integration
â”‚       â””â”€â”€ pinecone_db.py      # Pinecone alternative
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_ingest.py
â”‚   â”œâ”€â”€ test_retriever.py
â”‚   â”œâ”€â”€ test_llm.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml           # GitHub Actions CI/CD pipeline
â””â”€â”€ docker/
    â”œâ”€â”€ Dockerfile.backend
    â””â”€â”€ Dockerfile.frontend
```

---

ğŸ§± **ASCII Architecture Diagram**

```
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚       User / Client    â”‚
                                        â”‚  (Web UI, CLI, API)    â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚     FastAPI Backend    â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚               â”‚           â”‚               â”‚
                                â–¼               â–¼           â–¼               â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ Ingestion â”‚   â”‚ Retriever â”‚ â”‚ LLM QA    â”‚ â”‚ Evaluator â”‚
                          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                â”‚               â”‚           â”‚               â”‚
                                â–¼               â–¼           â–¼               â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ File Load â”‚   â”‚ Vector DB â”‚ â”‚ RAG       â”‚ â”‚ Metrics   â”‚
                          â”‚ & Parsing â”‚   â”‚  (FAISS/  â”‚ â”‚ Explainer â”‚ â”‚ (F1, EM,  â”‚
                          â”‚ (PDF/DOCX)â”‚   â”‚ Pinecone) â”‚ â”‚           â”‚ â”‚ BLEU, etc)â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

ğŸ§ª **Training & Ingestion Pipeline**

1. Collect diverse documents (PDF, DOCX, TXT)
2. Extract text and metadata
3. Chunk documents and generate embeddings
4. Store embeddings in vector DB (FAISS / Pinecone)
5. Evaluate QA retrieval, RAG explanations, and metrics
6. Fine-tune embedding model if necessary

---

ğŸ› ï¸ **Tool-Aware Reasoning**

* Grounded reasoning based on document embeddings
* Detects missing or ambiguous context
* Avoids hallucination by referencing only retrieved chunks

---

ğŸ“Š **Evaluation & Metrics**

* F1-score, Exact Match, ROUGE, BLEU
* Hallucination detection
* Retrieval relevance & ML strategy accuracy

---

ğŸŒ **Quick Start (Docker)**

```bash
docker build -t multi-doc-rag-qa .
docker run -p 8000:8000 multi-doc-rag-qa
```

Visit: [http://localhost:8000](http://localhost:8000)

---

âš–ï¸ **License**

Apache 2.0

---

âš ï¸ **Disclaimer**

Fully research-grade, open-source project.
No magical QA claims. Fully transparent, reproducible, and explainable.

---

ğŸ“˜ Detailed Case Study:

ğŸ”— Notion Portfolio: https://trail-bramble-8d5.notion.site/Naveen-Badiger-DevOps-Cloud-Engineer-300b680e255b80618978c2654214a6c6
